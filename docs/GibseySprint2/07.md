# 07\_smoke\_tests.md – **E2E Latency & Accuracy Guardrail**

> **Sprint 2 – Block 9–10 h**  |  Author ✍️ ***You + Gemini***
>
> **Goal:** Automated test suite + CI job that measures p95 latency, first‑token delay, and RAG hit‑rate after every deploy. Build fails if thresholds are exceeded.

---

## 1 KPIs & Thresholds

| Metric                                               | Target  | Fail if > |
| ---------------------------------------------------- | ------- | --------- |
| **p95 end‑to‑end latency** – time /ask → final token | ⩽ 2.5 s | 2.5 s     |
| **First‑token delay** – /ask → first SSE chunk       | ⩽ 0.6 s | 0.6 s     |
| **RAG miss‑rate** – responses lacking any page quote | ⩽ 10 %  | 10 %      |
| **Success %** – HTTP 200 responses                   | ≥ 98 %  | 98 %      |

---

## 2 Test Harness Options

* **Locust** for Pythonic load + custom assertions.
* **k6** (JS) for cloud scaling (optional).
* We’ll default to **Locust** here—lightweight and works in CI runner.

### 2.1 requirements-tests.txt

```
locust==2.24
orjson==3.10
pytest==8.2
```

---

## 3 Directory Layout

```
smoke/
  ├─ locustfile.py
  ├─ utils.py         # timers & parsing helpers
  ├─ rag_hit.py       # offline hit check
  └─ results_parser.py
.github/workflows/
  └─ smoke.yml
```

---

## 4 Core Code Highlights

### 4.1 utils.py

```python
import time, sseclient, requests, re

def ask(session, payload):
    start = time.perf_counter()
    resp  = session.post("http://character_chat:8002/ask", json=payload, stream=True)
    client = sseclient.SSEClient(resp)
    first_tok = None; chunks=[]
    for event in client.events():
        if first_tok is None:
            first_tok = time.perf_counter()
        chunks.append(event.data)
    total = time.perf_counter() - start
    first_delay = first_tok - start if first_tok else total
    text="".join(chunks)
    return total, first_delay, text

def has_quote(txt):
    return bool(re.search(r"\(p\.[0-9]+\)", txt))
```

### 4.2 locustfile.py

```python
from locust import HttpUser, task, between, events
from utils import ask, has_quote
import random, statistics, os

STUDENTS = ["brennan","alice","bob","maya"]
CHARS    = ["arieol","phillip","princhetta"]

class Reader(HttpUser):
    wait_time = between(0.3, 1)

    @task
    def chat(self):
        payload={
            "user_id": random.choice(STUDENTS),
            "char_id": random.choice(CHARS),
            "text": random.choice([
              "What is the mirror tower?",
              "Tell me about Shamrock Stillman",
              "Why are colors recursive?"
            ])
        }
        total, first, txt = ask(self.client, payload)
        self.environment.events.request_success.fire(
            request_type="ASK", name="/ask", response_time=total*1000, response_length=len(txt))
        # custom metrics
        events.request.fire(request_type="FIRST", name="first", response_time=first*1000, response_length=0)
        if not has_quote(txt):
            events.request_failure.fire(request_type="RAG", name="miss", response_time=total*1000, response_length=0, exception=Exception("noQuote"))
```

### 4.3 results\_parser.py

```python
import statistics, json

def evaluate(stats_file="stats.history.json"):
    data=json.load(open(stats_file))
    p95  = statistics.quantiles([r["response_time"] for r in data if r["name"]=="/ask"], n=20)[-1]
    first= statistics.quantiles([r["response_time"] for r in data if r["name"]=="first"], n=20)[-1]
    misses=sum(1 for r in data if r["name"]=="miss")
    total =sum(1 for r in data if r["name"]=="/ask")
    return {
      "p95": p95/1000, "first": first/1000,
      "rag_miss_rate": misses/total*100,
      "success_rate": 100-(misses/total*100)
    }
```

---

## 5 Running Locally

```bash
pip install -r requirements-tests.txt
locust -f smoke/locustfile.py --headless -u 40 -r 4 -t 1m --csv=smoke/stats
python smoke/results_parser.py > smoke/summary.json
cat smoke/summary.json
```

---

## 6 CI Integration (GitHub Actions)

`.github/workflows/smoke.yml`

```yaml
name: Smoke-Test
on:
  push:
    branches: [ "main", "sprint-2" ]
  pull_request:
    paths: [ 'character_chat/**', 'memory_rag/**', 'faust_worker/**' ]

jobs:
  smoke:
    runs-on: ubuntu-latest
    services:
      docker:
        image: docker:26.0-dind
        options: --privileged
    steps:
      - uses: actions/checkout@v4
      - name: Build stack
        run: docker compose -f docker-compose.ci.yml up -d
      - name: Run Locust suite
        run: |
          pip install -r requirements-tests.txt
          locust -f smoke/locustfile.py --headless -u 30 -r 3 -t 2m --csv=stats
      - name: Evaluate KPIs
        run: |
          python smoke/results_parser.py > metrics.json
          cat metrics.json
          python - <<'PY'
import json, sys
m=json.load(open('metrics.json'))
if m['p95']>2.5 or m['first']>0.6 or m['rag_miss_rate']>10 or m['success_rate']<98:
  print('❌ KPI breach', m)
  sys.exit(1)
print('✅ All thresholds good', m)
PY
```

*`docker-compose.ci.yml`* can build minimal images or pull from GHCR cache.

---

## 7 Troubleshooting

| Problem                    | Fix                                                                    |
| -------------------------- | ---------------------------------------------------------------------- |
| `Connection refused :8002` | chat service not up – add `depends_on` in CI compose.                  |
| High first‑token delay     | Ollama model swap or GPU busy – pin `-ngl 1` CPU.                      |
| RAG miss > 10 %            | Likely bad query slice; increase `k` param or improve quote Extractor. |

---

## 8 Delivery Checklist (30 min)

-\[ ] Implement Locustfile & helpers – 10 min

\- \[ ] Dry-run locally (10 min) ensure pass

\- \[ ] Add smoke.yml, push, watch CI (10 min)

* Merge gate: PR blocked if any KPI fails.
* `metrics.json` artifact stored per workflow for trend charts.
* Slack webhook posts green/red status.

*End of file 🧪*
